{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_6.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_CJlQriRq8QFcsSl6p3fKb_sFLaALvsO",
      "authorship_tag": "ABX9TyO4T3C35d2+1Ub3XGJJdgmD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falconlee236/DeepLearningFrom_Scratch/blob/main/ch06/Chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvptDX4-rJZl"
      },
      "source": [
        "# Chapter 6 technology about training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJiSI4bMwzEe"
      },
      "source": [
        "**6.1 pararmeter renew**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vL-wJ1txW9f"
      },
      "source": [
        "*6.1.2 Stochastic Gradient Descent(SGD)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqmymTItxecl"
      },
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        for key in params.keys():\n",
        "            params[key] -= self.lr * grads[key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX19LUYgx3kv"
      },
      "source": [
        "*6.1.4 Momentum*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzgqW3Xo0Xkf"
      },
      "source": [
        "class Momentum:\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = {}\n",
        "            for key, value in params.items():\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
        "            params[key] += self.v[key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1P7H7aJ1ngU"
      },
      "source": [
        "*6.1.5 AdaGrad*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZpwysH_1pda"
      },
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.h = None\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        if self.h is None:\n",
        "            self.h = {}\n",
        "            for key, val in params.items():\n",
        "                self.h[key] = np.zero_like(val)\n",
        "            \n",
        "        for key in params.keys():\n",
        "            self.h[key] += grads[key] * grads[key]\n",
        "            self.params[key] -= self.lr * grads[key] / np.sqrt(self.h[key] + le-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09g3rFV43hNz"
      },
      "source": [
        "**6.2 inital value of weight**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im4kIrZc3ipx"
      },
      "source": [
        "*6.2.2 activation value distribution of hidden layer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL-fh5sD6VsL"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "x = np.random.randn(1000, 100) # data of 1000\n",
        "node_num = 100 # node(neuron) number of each hidden layer\n",
        "hidden_layer_size = 5 # 5 number of hidden layer\n",
        "activations = {} # save activation value to this variable\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i - 1]\n",
        "    \n",
        "    w = np.random.randn(node_num, node_num) * 1\n",
        "    a = np.dot(x, w)\n",
        "    z = sigmoid(a)\n",
        "    activations[i] = z\n",
        "\n",
        "# histogram drawing\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nccGch7h8KXq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "x = np.random.randn(1000, 100) # data of 1000\n",
        "node_num = 100 # node(neuron) number of each hidden layer\n",
        "hidden_layer_size = 5 # 5 number of hidden layer\n",
        "activations = {} # save activation value to this variable\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i - 1]\n",
        "    \n",
        "    # w = np.random.randn(node_num, node_num) * 1\n",
        "    w = np.random.randn(node_num, node_num) * 0.01 # change std value 1 to 0.01\n",
        "    a = np.dot(x, w)\n",
        "    z = sigmoid(a)\n",
        "    activations[i] = z\n",
        "\n",
        "# histogram drawing\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lThmSaix9IH2"
      },
      "source": [
        "Activation value of each layer shoud be distribute much evenly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJDMvRwo9m8Q"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "x = np.random.randn(1000, 100) # data of 1000\n",
        "node_num = 100 # node(neuron) number of each hidden layer\n",
        "hidden_layer_size = 5 # 5 number of hidden layer\n",
        "activations = {} # save activation value to this variable\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i - 1]\n",
        "    \n",
        "    # w = np.random.randn(node_num, node_num) * 1\n",
        "    w = np.random.randn(node_num, node_num) / np.sqrt(node_num) # change std value\n",
        "    a = np.dot(x, w)\n",
        "    z = sigmoid(a)\n",
        "    activations[i] = z\n",
        "\n",
        "# histogram drawing\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRI7J7Jh98kc"
      },
      "source": [
        "**6.4 For correct training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEaw7om1cNDI"
      },
      "source": [
        "*6.4.3 DropOut*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfON6qoAcRLY"
      },
      "source": [
        "class Dropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "    \n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}